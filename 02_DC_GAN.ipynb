{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import os\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Arguments\n",
    "BATCH_SIZE = 256\n",
    "Z_DIM = 10\n",
    "LOAD_MODEL = False\n",
    "DB = 'MNIST' \n",
    "\n",
    "CHANNELS = 1\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "# Directories for storing data, model and output samples\n",
    "db_path = os.path.join('./data', DB)\n",
    "if not os.path.exists(db_path):\n",
    "    os.makedirs(db_path)\n",
    "model_path = os.path.join('./models', 'DC_GAN')\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "samples_path = os.path.join('./samples', 'DC_GAN')\n",
    "if not os.path.exists(samples_path):\n",
    "    os.makedirs(samples_path)\n",
    "\n",
    "# Data loader\n",
    "transform = transforms.Compose([transforms.Resize([32, 32]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "dataset = datasets.MNIST(db_path, train=True, download=True, transform=transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=4,\n",
    "                                        drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method for storing generated images\n",
    "def generate_imgs(z, epoch=0):\n",
    "    gen.eval()\n",
    "    fake_imgs = gen(z)\n",
    "    fake_imgs_ = vutils.make_grid(fake_imgs, normalize=True, nrow=math.ceil(BATCH_SIZE ** 0.5))\n",
    "    vutils.save_image(fake_imgs_, os.path.join(samples_path, 'sample_' + str(epoch) + '.png'))\n",
    "\n",
    "\n",
    "# Networks\n",
    "def conv_block(c_in, c_out, k_size=4, stride=2, pad=1, use_bn=True, transpose=False):\n",
    "    module = []\n",
    "    if transpose:\n",
    "        module.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
    "    else:\n",
    "        module.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
    "    if use_bn:\n",
    "        module.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*module)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, channels=3, conv_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.tconv1 = conv_block(z_dim, conv_dim * 4, pad=0, transpose=True)\n",
    "        self.tconv2 = conv_block(conv_dim * 4, conv_dim * 2, transpose=True)\n",
    "        self.tconv3 = conv_block(conv_dim * 2, conv_dim, transpose=True)\n",
    "        self.tconv4 = conv_block(conv_dim, channels, transpose=True, use_bn=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape([x.shape[0], -1, 1, 1])\n",
    "        x = F.relu(self.tconv1(x))\n",
    "        x = F.relu(self.tconv2(x))\n",
    "        x = F.relu(self.tconv3(x))\n",
    "        x = torch.tanh(self.tconv4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels=3, conv_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = conv_block(channels, conv_dim, use_bn=False)\n",
    "        self.conv2 = conv_block(conv_dim, conv_dim * 2)\n",
    "        self.conv3 = conv_block(conv_dim * 2, conv_dim * 4)\n",
    "        self.conv4 = conv_block(conv_dim * 4, 1, k_size=4, stride=1, pad=0, use_bn=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        alpha = 0.2\n",
    "        x = F.leaky_relu(self.conv1(x), alpha)\n",
    "        x = F.leaky_relu(self.conv2(x), alpha)\n",
    "        x = F.leaky_relu(self.conv3(x), alpha)\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x.squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Generator------------------\n",
      "Generator(\n",
      "  (tconv1): Sequential(\n",
      "    (0): ConvTranspose2d(10, 256, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv2): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv3): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv4): Sequential(\n",
      "    (0): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "------------------Discriminator------------------\n",
      "Discriminator(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 1/10\titer: 0/234\ttotal_iters: 1\td_loss:0.8043\tg_loss:3.8284\n",
      "Epoch: 1/10\titer: 50/234\ttotal_iters: 51\td_loss:0.0453\tg_loss:4.4462\n",
      "Epoch: 1/10\titer: 100/234\ttotal_iters: 101\td_loss:1.1104\tg_loss:2.1807\n",
      "Epoch: 1/10\titer: 150/234\ttotal_iters: 151\td_loss:0.2826\tg_loss:1.6803\n",
      "Epoch: 1/10\titer: 200/234\ttotal_iters: 201\td_loss:0.5094\tg_loss:2.8162\n",
      "Epoch: 2/10\titer: 0/234\ttotal_iters: 235\td_loss:0.4796\tg_loss:0.8726\n",
      "Epoch: 2/10\titer: 50/234\ttotal_iters: 285\td_loss:0.4559\tg_loss:1.2111\n",
      "Epoch: 2/10\titer: 100/234\ttotal_iters: 335\td_loss:0.4997\tg_loss:2.958\n",
      "Epoch: 2/10\titer: 150/234\ttotal_iters: 385\td_loss:0.4863\tg_loss:1.0004\n",
      "Epoch: 2/10\titer: 200/234\ttotal_iters: 435\td_loss:0.4034\tg_loss:1.6267\n",
      "Epoch: 3/10\titer: 0/234\ttotal_iters: 469\td_loss:0.6828\tg_loss:0.5355\n",
      "Epoch: 3/10\titer: 50/234\ttotal_iters: 519\td_loss:0.5017\tg_loss:1.8072\n",
      "Epoch: 3/10\titer: 100/234\ttotal_iters: 569\td_loss:0.5388\tg_loss:1.7745\n",
      "Epoch: 3/10\titer: 150/234\ttotal_iters: 619\td_loss:0.6208\tg_loss:2.0653\n",
      "Epoch: 3/10\titer: 200/234\ttotal_iters: 669\td_loss:0.7218\tg_loss:2.4965\n",
      "Epoch: 4/10\titer: 0/234\ttotal_iters: 703\td_loss:0.5159\tg_loss:1.062\n",
      "Epoch: 4/10\titer: 50/234\ttotal_iters: 753\td_loss:0.5178\tg_loss:1.3374\n",
      "Epoch: 4/10\titer: 100/234\ttotal_iters: 803\td_loss:0.4931\tg_loss:1.1003\n",
      "Epoch: 4/10\titer: 150/234\ttotal_iters: 853\td_loss:0.565\tg_loss:0.5874\n",
      "Epoch: 4/10\titer: 200/234\ttotal_iters: 903\td_loss:0.5301\tg_loss:0.6433\n",
      "Epoch: 5/10\titer: 0/234\ttotal_iters: 937\td_loss:0.5069\tg_loss:0.9762\n",
      "Epoch: 5/10\titer: 50/234\ttotal_iters: 987\td_loss:0.5579\tg_loss:1.3048\n",
      "Epoch: 5/10\titer: 100/234\ttotal_iters: 1037\td_loss:0.4719\tg_loss:1.3814\n",
      "Epoch: 5/10\titer: 150/234\ttotal_iters: 1087\td_loss:0.5367\tg_loss:0.8885\n",
      "Epoch: 5/10\titer: 200/234\ttotal_iters: 1137\td_loss:0.5495\tg_loss:1.6282\n",
      "Epoch: 6/10\titer: 0/234\ttotal_iters: 1171\td_loss:0.5244\tg_loss:1.4165\n",
      "Epoch: 6/10\titer: 50/234\ttotal_iters: 1221\td_loss:0.4631\tg_loss:0.9332\n",
      "Epoch: 6/10\titer: 100/234\ttotal_iters: 1271\td_loss:0.4628\tg_loss:1.4552\n",
      "Epoch: 6/10\titer: 150/234\ttotal_iters: 1321\td_loss:0.4462\tg_loss:1.5769\n",
      "Epoch: 6/10\titer: 200/234\ttotal_iters: 1371\td_loss:0.4291\tg_loss:1.5322\n",
      "Epoch: 7/10\titer: 0/234\ttotal_iters: 1405\td_loss:0.4374\tg_loss:1.6759\n",
      "Epoch: 7/10\titer: 50/234\ttotal_iters: 1455\td_loss:0.417\tg_loss:1.3914\n",
      "Epoch: 7/10\titer: 100/234\ttotal_iters: 1505\td_loss:0.4137\tg_loss:1.8621\n",
      "Epoch: 7/10\titer: 150/234\ttotal_iters: 1555\td_loss:0.5073\tg_loss:1.0106\n",
      "Epoch: 7/10\titer: 200/234\ttotal_iters: 1605\td_loss:0.4184\tg_loss:1.7688\n",
      "Epoch: 8/10\titer: 0/234\ttotal_iters: 1639\td_loss:0.4552\tg_loss:1.1693\n",
      "Epoch: 8/10\titer: 50/234\ttotal_iters: 1689\td_loss:0.3661\tg_loss:1.2769\n",
      "Epoch: 8/10\titer: 100/234\ttotal_iters: 1739\td_loss:0.4094\tg_loss:1.7151\n",
      "Epoch: 8/10\titer: 150/234\ttotal_iters: 1789\td_loss:0.2476\tg_loss:2.3736\n",
      "Epoch: 8/10\titer: 200/234\ttotal_iters: 1839\td_loss:0.2414\tg_loss:2.0349\n",
      "Epoch: 9/10\titer: 0/234\ttotal_iters: 1873\td_loss:0.2493\tg_loss:2.0358\n",
      "Epoch: 9/10\titer: 50/234\ttotal_iters: 1923\td_loss:0.1968\tg_loss:2.1746\n",
      "Epoch: 9/10\titer: 100/234\ttotal_iters: 1973\td_loss:0.3548\tg_loss:2.209\n",
      "Epoch: 9/10\titer: 150/234\ttotal_iters: 2023\td_loss:0.1633\tg_loss:2.5506\n",
      "Epoch: 9/10\titer: 200/234\ttotal_iters: 2073\td_loss:0.1731\tg_loss:2.6836\n",
      "Epoch: 10/10\titer: 0/234\ttotal_iters: 2107\td_loss:0.1425\tg_loss:3.5237\n",
      "Epoch: 10/10\titer: 50/234\ttotal_iters: 2157\td_loss:0.1662\tg_loss:2.2857\n",
      "Epoch: 10/10\titer: 100/234\ttotal_iters: 2207\td_loss:0.7443\tg_loss:2.0874\n",
      "Epoch: 10/10\titer: 150/234\ttotal_iters: 2257\td_loss:0.1179\tg_loss:2.8681\n",
      "Epoch: 10/10\titer: 200/234\ttotal_iters: 2307\td_loss:0.2604\tg_loss:1.7208\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(z_dim=Z_DIM, channels=CHANNELS)\n",
    "dis = Discriminator(channels=CHANNELS)\n",
    "\n",
    "# Load previous model   \n",
    "if LOAD_MODEL:\n",
    "    gen.load_state_dict(torch.load(os.path.join(model_path, 'gen.pkl')))\n",
    "    dis.load_state_dict(torch.load(os.path.join(model_path, 'dis.pkl')))\n",
    "\n",
    "# Model Summary\n",
    "print(\"------------------Generator------------------\")\n",
    "print(gen)\n",
    "print(\"------------------Discriminator------------------\")\n",
    "print(dis)\n",
    "\n",
    "# Define Optimizers\n",
    "g_opt = optim.Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "d_opt = optim.Adam(dis.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "\n",
    "# Loss functions\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Fix images for viz\n",
    "fixed_z = torch.randn(BATCH_SIZE, Z_DIM)\n",
    "\n",
    "# Labels\n",
    "real_label = torch.ones(BATCH_SIZE)\n",
    "fake_label = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "# GPU Compatibility\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    gen, dis = gen.cuda(), dis.cuda()\n",
    "    real_label, fake_label = real_label.cuda(), fake_label.cuda()\n",
    "    fixed_z = fixed_z.cuda()\n",
    "\n",
    "total_iters = 0\n",
    "max_iter = len(data_loader)\n",
    "# Training\n",
    "for epoch in range(EPOCHS):\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "\n",
    "        total_iters += 1\n",
    "\n",
    "        # Loading data\n",
    "        x_real, _ = data\n",
    "        z_fake = torch.randn(BATCH_SIZE, Z_DIM)\n",
    "\n",
    "        if is_cuda:\n",
    "            x_real = x_real.cuda()\n",
    "            z_fake = z_fake.cuda()\n",
    "\n",
    "        # Generate fake data\n",
    "        x_fake = gen(z_fake)\n",
    "\n",
    "        # Train Discriminator\n",
    "        fake_out = dis(x_fake.detach())\n",
    "        real_out = dis(x_real.detach())\n",
    "        d_loss = (loss_fn(fake_out, fake_label) + loss_fn(real_out, real_label)) / 2\n",
    "\n",
    "        d_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        # Train Generator\n",
    "        fake_out = dis(x_fake)\n",
    "        g_loss = loss_fn(fake_out, real_label)\n",
    "\n",
    "        g_opt.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(EPOCHS)\n",
    "                  + \"\\titer: \" + str(i) + \"/\" + str(max_iter)\n",
    "                  + \"\\ttotal_iters: \" + str(total_iters)\n",
    "                  + \"\\td_loss:\" + str(round(d_loss.item(), 4))\n",
    "                  + \"\\tg_loss:\" + str(round(g_loss.item(), 4))\n",
    "                  )\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        generate_imgs(fixed_z, epoch=epoch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_imgs(fixed_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, file_name='checkpoint.pth.tar'):\n",
    "    path = \"./models/DC_GAN/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    torch.save(state, path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving params.\n",
    "save_checkpoint({'epoch': epoch + 1, 'state_dict':dis.state_dict(), 'optimizer' : d_opt.state_dict()}, 'D_c.pth.tar')\n",
    "save_checkpoint({'epoch': epoch + 1, 'state_dict':gen.state_dict(), 'optimizer' : g_opt.state_dict()}, 'G_c.pth.tar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
