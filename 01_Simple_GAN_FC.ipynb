{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simple GAN using fully connected layers\n",
    "for generating digit '4'\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 0.0001\n",
    "z_dim = 64\n",
    "image_dim = 28 * 28 * 1  # 784\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "discriminator = Discriminator(image_dim).to(device)\n",
    "generator = Generator(z_dim, image_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root=\"data/\", transform=transforms, download=True)\n",
    "# Assuming 'data' is the tensor containing the images\n",
    "# Assuming 'dataset' is the MNIST dataset\n",
    "\n",
    "# Get the labels of the dataset\n",
    "labels = dataset.targets.numpy()\n",
    "\n",
    "# Find the indices of images with label 4\n",
    "indices = np.where(labels == 4)[0]\n",
    "dataset_4 = torch.utils.data.Subset(dataset, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = DataLoader(dataset_4, batch_size=batch_size, shuffle=True)\n",
    "opt_discriminator = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "opt_generator = optim.Adam(generator.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 0/183                       Loss D: 0.6707, loss G: 0.6509\n",
      "Epoch [1/50] Batch 0/183                       Loss D: 0.5585, loss G: 0.5209\n",
      "Epoch [2/50] Batch 0/183                       Loss D: 0.3528, loss G: 0.9538\n",
      "Epoch [3/50] Batch 0/183                       Loss D: 0.4885, loss G: 0.7892\n",
      "Epoch [4/50] Batch 0/183                       Loss D: 0.5631, loss G: 0.6847\n",
      "Epoch [5/50] Batch 0/183                       Loss D: 0.4107, loss G: 1.0072\n",
      "Epoch [6/50] Batch 0/183                       Loss D: 0.5691, loss G: 0.7300\n",
      "Epoch [7/50] Batch 0/183                       Loss D: 0.6552, loss G: 0.6506\n",
      "Epoch [8/50] Batch 0/183                       Loss D: 0.6001, loss G: 0.7288\n",
      "Epoch [9/50] Batch 0/183                       Loss D: 0.6768, loss G: 0.6863\n",
      "Epoch [10/50] Batch 0/183                       Loss D: 0.4891, loss G: 0.9789\n",
      "Epoch [11/50] Batch 0/183                       Loss D: 0.4475, loss G: 1.0127\n",
      "Epoch [12/50] Batch 0/183                       Loss D: 0.5134, loss G: 0.9503\n",
      "Epoch [13/50] Batch 0/183                       Loss D: 0.7202, loss G: 0.6319\n",
      "Epoch [14/50] Batch 0/183                       Loss D: 0.6313, loss G: 0.7603\n",
      "Epoch [15/50] Batch 0/183                       Loss D: 0.6324, loss G: 0.7329\n",
      "Epoch [16/50] Batch 0/183                       Loss D: 0.4656, loss G: 1.0158\n",
      "Epoch [17/50] Batch 0/183                       Loss D: 0.5313, loss G: 0.8797\n",
      "Epoch [18/50] Batch 0/183                       Loss D: 0.4251, loss G: 1.1199\n",
      "Epoch [19/50] Batch 0/183                       Loss D: 0.5618, loss G: 0.8567\n",
      "Epoch [20/50] Batch 0/183                       Loss D: 0.4445, loss G: 1.0051\n",
      "Epoch [21/50] Batch 0/183                       Loss D: 0.4441, loss G: 1.0108\n",
      "Epoch [22/50] Batch 0/183                       Loss D: 0.6376, loss G: 0.7673\n",
      "Epoch [23/50] Batch 0/183                       Loss D: 0.5186, loss G: 0.8815\n",
      "Epoch [24/50] Batch 0/183                       Loss D: 0.4978, loss G: 0.9435\n",
      "Epoch [25/50] Batch 0/183                       Loss D: 0.6559, loss G: 0.7279\n",
      "Epoch [26/50] Batch 0/183                       Loss D: 0.5747, loss G: 0.8417\n",
      "Epoch [27/50] Batch 0/183                       Loss D: 0.8094, loss G: 0.6752\n",
      "Epoch [28/50] Batch 0/183                       Loss D: 0.6445, loss G: 0.7836\n",
      "Epoch [29/50] Batch 0/183                       Loss D: 0.7768, loss G: 0.6765\n",
      "Epoch [30/50] Batch 0/183                       Loss D: 0.6323, loss G: 0.7707\n",
      "Epoch [31/50] Batch 0/183                       Loss D: 0.5549, loss G: 0.8199\n",
      "Epoch [32/50] Batch 0/183                       Loss D: 0.4624, loss G: 1.1209\n",
      "Epoch [33/50] Batch 0/183                       Loss D: 0.5882, loss G: 0.8845\n",
      "Epoch [34/50] Batch 0/183                       Loss D: 0.5106, loss G: 0.9923\n",
      "Epoch [35/50] Batch 0/183                       Loss D: 0.4283, loss G: 1.1519\n",
      "Epoch [36/50] Batch 0/183                       Loss D: 0.2989, loss G: 1.4023\n",
      "Epoch [37/50] Batch 0/183                       Loss D: 0.4363, loss G: 1.0458\n",
      "Epoch [38/50] Batch 0/183                       Loss D: 0.3925, loss G: 1.1933\n",
      "Epoch [39/50] Batch 0/183                       Loss D: 0.4564, loss G: 1.0781\n",
      "Epoch [40/50] Batch 0/183                       Loss D: 0.5379, loss G: 0.9450\n",
      "Epoch [41/50] Batch 0/183                       Loss D: 0.5376, loss G: 0.8886\n",
      "Epoch [42/50] Batch 0/183                       Loss D: 0.4082, loss G: 1.0746\n",
      "Epoch [43/50] Batch 0/183                       Loss D: 0.6736, loss G: 0.7281\n",
      "Epoch [44/50] Batch 0/183                       Loss D: 0.5729, loss G: 0.8643\n",
      "Epoch [45/50] Batch 0/183                       Loss D: 0.4967, loss G: 1.0365\n",
      "Epoch [46/50] Batch 0/183                       Loss D: 0.4829, loss G: 1.0210\n",
      "Epoch [47/50] Batch 0/183                       Loss D: 0.4353, loss G: 1.2244\n",
      "Epoch [48/50] Batch 0/183                       Loss D: 0.4195, loss G: 1.2460\n",
      "Epoch [49/50] Batch 0/183                       Loss D: 0.2277, loss G: 1.7344\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        # print(\"line 4: \",batch_idx,real.shape,_.shape)\n",
    "        real = real.view(-1, 784).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = generator(noise)\n",
    "        disc_real = discriminator(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = discriminator(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        discriminator.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_discriminator.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        # where the second option of maximizing doesn't suffer from\n",
    "        # saturating gradients\n",
    "        output = discriminator(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        generator.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_generator.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                # Save fake image as PNG\n",
    "                # if floder not exist, create it\n",
    "                import os\n",
    "                if not os.path.exists(\"logs/fake\"):\n",
    "                    os.makedirs(\"logs/fake\")\n",
    "                if not os.path.exists(\"logs/real\"):\n",
    "                    os.makedirs(\"logs/real\")\n",
    "                vutils.save_image(img_grid_fake, f\"logs/fake/{epoch}.png\", normalize=True)\n",
    "                vutils.save_image(img_grid_real, f\"logs/real/{epoch}.png\", normalize=True)\n",
    "\n",
    "\n",
    "                step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
