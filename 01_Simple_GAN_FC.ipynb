{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simple GAN using fully connected layers\n",
    "for generating digit '4'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 0.0001\n",
    "z_dim = 64\n",
    "image_dim = 28 * 28 * 1  # 784\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "discriminator = Discriminator(image_dim).to(device)\n",
    "generator = Generator(z_dim, image_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root=\"data/\", transform=_transforms, download=True)\n",
    "# Assuming 'data' is the tensor containing the images\n",
    "# Assuming 'dataset' is the MNIST dataset\n",
    "\n",
    "# Get the labels of the dataset\n",
    "labels = dataset.targets.numpy()\n",
    "\n",
    "# Find the indices of images with label 4\n",
    "indices = np.where(labels == 4)[0]\n",
    "dataset_4 = torch.utils.data.Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset_4, batch_size=batch_size, shuffle=True)\n",
    "opt_discriminator = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "opt_generator = optim.Adam(generator.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20] Batch 0/92                       Loss D: 0.7434, loss G: 0.7196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Batch 0/92                       Loss D: 0.4329, loss G: 0.6701\n",
      "Epoch [2/20] Batch 0/92                       Loss D: 0.5366, loss G: 0.5765\n",
      "Epoch [3/20] Batch 0/92                       Loss D: 0.3993, loss G: 0.8982\n",
      "Epoch [4/20] Batch 0/92                       Loss D: 0.4154, loss G: 0.8428\n",
      "Epoch [5/20] Batch 0/92                       Loss D: 0.4894, loss G: 0.7870\n",
      "Epoch [6/20] Batch 0/92                       Loss D: 0.5571, loss G: 0.6766\n",
      "Epoch [7/20] Batch 0/92                       Loss D: 0.5801, loss G: 0.6787\n",
      "Epoch [8/20] Batch 0/92                       Loss D: 0.4462, loss G: 0.9090\n",
      "Epoch [9/20] Batch 0/92                       Loss D: 0.5459, loss G: 0.7619\n",
      "Epoch [10/20] Batch 0/92                       Loss D: 0.5038, loss G: 0.8274\n",
      "Epoch [11/20] Batch 0/92                       Loss D: 0.6355, loss G: 0.6682\n",
      "Epoch [12/20] Batch 0/92                       Loss D: 0.4765, loss G: 0.9166\n",
      "Epoch [13/20] Batch 0/92                       Loss D: 0.5371, loss G: 0.7773\n",
      "Epoch [14/20] Batch 0/92                       Loss D: 0.6349, loss G: 0.6872\n",
      "Epoch [15/20] Batch 0/92                       Loss D: 0.5806, loss G: 0.7925\n",
      "Epoch [16/20] Batch 0/92                       Loss D: 0.5402, loss G: 0.8398\n",
      "Epoch [17/20] Batch 0/92                       Loss D: 0.6162, loss G: 0.7374\n",
      "Epoch [18/20] Batch 0/92                       Loss D: 0.5806, loss G: 0.8203\n",
      "Epoch [19/20] Batch 0/92                       Loss D: 0.5604, loss G: 0.8614\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        # print(\"line 4: \",batch_idx,real.shape,_.shape)\n",
    "        real = real.view(-1, 784).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = generator(noise)\n",
    "        disc_real = discriminator(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = discriminator(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        discriminator.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_discriminator.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        # where the second option of maximizing doesn't suffer from\n",
    "        # saturating gradients\n",
    "        output = discriminator(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        generator.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_generator.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                # Save fake image as PNG\n",
    "                # if floder not exist, create it\n",
    "                import os\n",
    "\n",
    "                if not os.path.exists(\"logs/fake\"):\n",
    "                    os.makedirs(\"logs/fake\")\n",
    "                if not os.path.exists(\"logs/real\"):\n",
    "                    os.makedirs(\"logs/real\")\n",
    "                vutils.save_image(\n",
    "                    img_grid_fake, f\"logs/fake/{epoch}.png\", normalize=True\n",
    "                )\n",
    "                vutils.save_image(\n",
    "                    img_grid_real, f\"logs/real/{epoch}.png\", normalize=True\n",
    "                )\n",
    "\n",
    "                step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
